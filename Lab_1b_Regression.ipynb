{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcxiSlnPk0LZ/mwgSiU2PO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mersalas/MLBS-2025_workshop/blob/main/Lab_1b_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "C7ZF2eIjE_Mq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gijnMuUID5kH",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "!pip install ucimlrepo\n",
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.plots import plot_objective\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "3p0lG-7bHR3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load dataset**"
      ],
      "metadata": {
        "id": "jgUMkrDyHeJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch dataset\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "abalone = fetch_ucirepo(id=1)"
      ],
      "metadata": {
        "id": "VmKHtgfXHaHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploratory data analysis**"
      ],
      "metadata": {
        "id": "UXrL7Kr4nDGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data (as pandas dataframes)\n",
        "X = abalone.data.features\n",
        "y = abalone.data.targets\n",
        "X.head()"
      ],
      "metadata": {
        "id": "AvAle4m_H0wQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add y into X dataset\n",
        "data = X.copy()\n",
        "data['Rings'] = y\n",
        "data.head()"
      ],
      "metadata": {
        "id": "INiff-KvZ3TX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata\n",
        "print(abalone.metadata)"
      ],
      "metadata": {
        "id": "50PN2-fXIV4Z",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable information\n",
        "print(abalone.variables)"
      ],
      "metadata": {
        "id": "9J7G6THkIYp4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Countplot for variable sex\n",
        "ax = sns.countplot(x='Sex', data=data)\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BhOqZHj_pLsO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical into numerical values\n",
        "label = LabelEncoder()\n",
        "data['Sex'] = label.fit_transform(data['Sex'])"
      ],
      "metadata": {
        "id": "-djOErpwYzR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check datatypes & if there are missing values\n",
        "data.info()"
      ],
      "metadata": {
        "id": "C154gyxGJiOO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary statistics\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "d8S7C3D7Kzhy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many samples have zero (0) values for height?\n",
        "(data.Height == 0).sum()"
      ],
      "metadata": {
        "id": "7aknXrl6U5Sb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the samples with height = 0\n",
        "data[data['Height'] == 0]"
      ],
      "metadata": {
        "id": "tLStc7vqYJz1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop samples with height = 0\n",
        "data = data[data['Height'] != 0]\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "IqtOjsxXboIn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert rings to the age of abalone\n",
        "data['Age'] = data['Rings'] + 1.5\n",
        "\n",
        "# Remove rings column\n",
        "data = data.drop('Rings', axis=1)\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "1NrU9qSwdKHo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "sns.heatmap(data.corr(), annot=True)"
      ],
      "metadata": {
        "id": "50XCVALQfT_f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot\n",
        "\n",
        "# Define numeric features\n",
        "numeric_features = ['Length', 'Diameter', 'Height', 'Whole_weight',\n",
        "                    'Shucked_weight', 'Viscera_weight', 'Shell_weight', 'Sex']\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(4,2, figsize=(12,14))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Plot scatter plots for each numeric feature against age\n",
        "for i, feature in enumerate(numeric_features):\n",
        "  sns.scatterplot(data=data, x=feature, y='Age', ax=axes[i])\n",
        "  axes[i].set_title(f\"{feature} vs Age\")\n",
        "  axes[i].set_xlabel(feature)\n",
        "  axes[i].set_ylabel('Age')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G87l7H872xua",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating the features from the target\n",
        "X = data.iloc[:,0:8].values\n",
        "y = data['Age'].values"
      ],
      "metadata": {
        "id": "_OO28eJ-ft_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target distribution\n",
        "sns.distplot(y)"
      ],
      "metadata": {
        "id": "5agUmxwZ9M4i",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plot to detect outliers\n",
        "sns.boxplot(y)"
      ],
      "metadata": {
        "id": "qfX9g_zaoeFn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scale = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "-pFv5u6rtkea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training & test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.20, random_state=42)\n",
        "\n",
        "print(\"Size of training set: {}   Size of test set:\"\n",
        "      \" {}\\n\".format(X_train.shape[0], X_test.shape[0]))"
      ],
      "metadata": {
        "id": "UGgwsbbiwx1M",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train model**"
      ],
      "metadata": {
        "id": "dfgRn0CK4gR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridge regression"
      ],
      "metadata": {
        "id": "1VuswLy74cir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Bayesian search to find optimum parameters for ridge\n",
        "ridge = Ridge(random_state=42)\n",
        "\n",
        "param = {'alpha': (1e-3, 1e1, 'log-uniform')}\n",
        "\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "ridge_cv = BayesSearchCV(estimator=ridge, search_spaces=param, cv=cv, scoring='r2',\n",
        "                       n_jobs=-1, random_state=42)\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "\n",
        "print('best parameters: ', ridge_cv.best_params_)\n",
        "print('best score after search cv:', ridge_cv.best_score_)"
      ],
      "metadata": {
        "id": "QwN87hxe2cj_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the Bayesian objective function\n",
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "plot_objective(ridge_cv.optimizer_results_[0], ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G3Wr58MO6wCi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ridge\n",
        "ridge_tuned = Ridge(**ridge_cv.best_params_, random_state=42)\n",
        "\n",
        "ridge_tuned.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "RCkLT6Oi8OJ7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print intercept & coefficients\n",
        "print('intercept:', ridge_tuned.intercept_ )\n",
        "print('coef:', ridge_tuned.coef_, end='\\n')"
      ],
      "metadata": {
        "id": "cMkcXcIZ8-jx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the ridge model on the training set\n",
        "scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
        "cv_results = cross_validate(ridge_tuned, X_train, y_train, cv=10, scoring=scoring, n_jobs=-1)\n",
        "\n",
        "print(\"Performance of the ridge model on the training set:\\nR2: {:.4f}\\nMSE: {:.4f}\\nMAE: {:.4f}\".format(\n",
        "    np.mean(cv_results['test_r2']),\n",
        "    np.mean(cv_results['test_neg_mean_squared_error']),\n",
        "    np.mean(cv_results['test_neg_mean_absolute_error'])\n",
        "))"
      ],
      "metadata": {
        "id": "2kLntFeM9N-U",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lasso regression"
      ],
      "metadata": {
        "id": "_jj33puBdixD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Bayesian search to find optimum parameters for lasso\n",
        "lasso = Lasso(random_state=42)\n",
        "\n",
        "param = {'alpha': (1e-3, 1, 'log-uniform')}\n",
        "\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "lasso_cv = BayesSearchCV(estimator=lasso, search_spaces=param, cv=cv, scoring='r2',\n",
        "                       n_jobs=-1, random_state=42)\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "\n",
        "print('best parameters: ', lasso_cv.best_params_)\n",
        "print('best score after search cv:', lasso_cv.best_score_)"
      ],
      "metadata": {
        "id": "eQaPQ9XtdEv5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the Bayesian objective function\n",
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "plot_objective(lasso_cv.optimizer_results_[0], ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KmTFoAoEdFH5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train lasso\n",
        "lasso_tuned = Lasso(**lasso_cv.best_params_, random_state=42)\n",
        "\n",
        "lasso_tuned.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "MDryVBPOdFff",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print intercept & coefficients\n",
        "print('intercept:', lasso_tuned.intercept_ )\n",
        "print('coef:', lasso_tuned.coef_, end='\\n')"
      ],
      "metadata": {
        "id": "j20_BNWqfNnc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the lasso model on the training set\n",
        "scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
        "cv_results = cross_validate(lasso_tuned, X_train, y_train, cv=10, scoring=scoring, n_jobs=-1)\n",
        "\n",
        "print(\"Performance of the lasso model on the training set:\\nR2: {:.4f}\\nMSE: {:.4f}\\nMAE: {:.4f}\".format(\n",
        "    np.mean(cv_results['test_r2']),\n",
        "    np.mean(cv_results['test_neg_mean_squared_error']),\n",
        "    np.mean(cv_results['test_neg_mean_absolute_error'])\n",
        "))"
      ],
      "metadata": {
        "id": "Njlitne8fZqb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ElasticNet regression"
      ],
      "metadata": {
        "id": "nVD-OdKJfwqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Bayesian search to find optimum parameters for elasticnet\n",
        "enet = ElasticNet(random_state=42)\n",
        "\n",
        "param = {'alpha': (1e-3, 1, 'log-uniform'),\n",
        "         'l1_ratio': (0,1)}\n",
        "\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "enet_cv = BayesSearchCV(estimator=enet, search_spaces=param, cv=cv, scoring='r2',\n",
        "                       n_jobs=-1, random_state=42)\n",
        "enet_cv.fit(X_train, y_train)\n",
        "\n",
        "print('best parameters: ', enet_cv.best_params_)\n",
        "print('best score after search cv:', enet_cv.best_score_)"
      ],
      "metadata": {
        "id": "A2YnangagGDx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the Bayesian objective function\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "plot_objective(enet_cv.optimizer_results_[0], ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tmwp0IKvgGGv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train enet\n",
        "enet_tuned = ElasticNet(**enet_cv.best_params_, random_state=42)\n",
        "\n",
        "enet_tuned.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vGZAXE4TgGJ4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print intercept & coefficients\n",
        "print('intercept:', enet_tuned.intercept_ )\n",
        "print('coef:', enet_tuned.coef_, end='\\n')"
      ],
      "metadata": {
        "id": "uKcEwUW7gGNP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the enet model on the training set\n",
        "scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
        "cv_results = cross_validate(enet_tuned, X_train, y_train, cv=10, scoring=scoring, n_jobs=-1)\n",
        "\n",
        "print(\"Performance of the enet model on the training set:\\nR2: {:.4f}\\nMSE: {:.4f}\\nMAE: {:.4f}\".format(\n",
        "    np.mean(cv_results['test_r2']),\n",
        "    np.mean(cv_results['test_neg_mean_squared_error']),\n",
        "    np.mean(cv_results['test_neg_mean_absolute_error'])\n",
        "))"
      ],
      "metadata": {
        "id": "gqTwSb0ggUW6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNR"
      ],
      "metadata": {
        "id": "5JCp1fVSk1T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform random search to find the optimum parameters for KNR\n",
        "knr = KNeighborsRegressor(n_jobs=-1)\n",
        "\n",
        "param = {'n_neighbors': (5, 20),\n",
        "         'weights': ['uniform', 'distance'],\n",
        "         'p': (1,2,3),\n",
        "         'metric': ['minkowski', 'manhattan', 'euclidean']\n",
        "         }\n",
        "\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "knr_cv = BayesSearchCV(estimator=knr, search_spaces=param, cv=cv, scoring='r2',\n",
        "                       n_jobs=-1, random_state=42)\n",
        "\n",
        "knr_cv.fit(X_train, y_train)\n",
        "\n",
        "print('best parameters: ', knr_cv.best_params_)\n",
        "print('best score after random search cv:', knr_cv.best_score_)"
      ],
      "metadata": {
        "id": "Xj0kM0J2gGSi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the Bayesian objective function\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "plot_objective(knr_cv.optimizer_results_[0], ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "16fZsFfGlJ1P",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train KNR\n",
        "knr_tuned = KNeighborsRegressor(n_neighbors=17, weights='distance', p=2,\n",
        "                                 metric='euclidean', n_jobs=-1)\n",
        "\n",
        "knr_tuned.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ZNBuTV9mlJ35",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the KNR model on the training set\n",
        "scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
        "cv_results = cross_validate(knr_tuned, X_train, y_train, cv=10, scoring=scoring, n_jobs=-1)\n",
        "\n",
        "print(\"Performance of the enet model on the training set:\\nR2: {:.4f}\\nMSE: {:.4f}\\nMAE: {:.4f}\".format(\n",
        "    np.mean(cv_results['test_r2']),\n",
        "    np.mean(cv_results['test_neg_mean_squared_error']),\n",
        "    np.mean(cv_results['test_neg_mean_absolute_error'])\n",
        "))"
      ],
      "metadata": {
        "id": "mXlHghVWlJ9-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation**"
      ],
      "metadata": {
        "id": "Rx03K4C1qBVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual plot\n",
        "y_train_pred = knr_tuned.predict(X_train)\n",
        "y_test_pred = knr_tuned.predict(X_test)\n",
        "\n",
        "x_max = np.max([np.max(y_train_pred), np.max(y_test_pred)])\n",
        "x_min = np.min([np.min(y_train_pred), np.min(y_test_pred)])\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7,3), sharey=True)\n",
        "\n",
        "ax1.scatter(\n",
        "    y_test_pred, y_test_pred - y_test,\n",
        "    c='limegreen', marker='s',\n",
        "    edgecolor='white', label='Test data')\n",
        "\n",
        "ax2.scatter(\n",
        "    y_train_pred, y_train_pred - y_train,\n",
        "    c='steelblue', marker='o', edgecolor='white',\n",
        "    label='Training data')\n",
        "ax1.set_ylabel('Residuals')\n",
        "\n",
        "for ax in (ax1, ax2):\n",
        "  ax.set_xlabel('Predicted values')\n",
        "  ax.legend(loc='upper left')\n",
        "  ax.hlines(y=0, xmin=x_min-100, xmax=x_max+100,\\\n",
        "            color='black', lw=2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yk15idc6Oj9q",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_knr = knr_tuned.predict(X_test)\n",
        "\n",
        "print(\"Performance of the KNR model on the test set:\")\n",
        "print(\"R2: {:.4f}\".format(r2_score(y_test, y_pred_knr)))\n",
        "print(\"MSE: {:.4f}\".format(mean_squared_error(y_test, y_pred_knr)))\n",
        "print(\"MAE: {:.4f}\".format(mean_absolute_error(y_test, y_pred_knr)))"
      ],
      "metadata": {
        "id": "2w-DzhD-ciub",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 1b**"
      ],
      "metadata": {
        "id": "hyTNQr5xrTt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the abalone dataset, build regressor using the following algorithms:\n",
        "\n",
        "\n",
        "*   SVR\n",
        "*   RandomForestRegressor\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ukDRWuH8rUbV"
      }
    }
  ]
}